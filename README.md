# ABSTRACT
## Sound classification plays a critical role in various fields such as speech recognition, music genre detection, and instrument identification. Traditional methods, often relying on handcrafted features, have limitations in achieving high accuracy rates. However, recent advancements in deep learning have led to significant improvements in this area. Particularly, transformer models have demonstrated powerful capabilities in representing and classifying audio data, enhancing performance. This study aims to classify note sounds in different octaves, obtained from various musical instruments, using transformer-based models. The research encompasses a comprehensive process involving both dataset creation and model evaluation. In the dataset creation phase, musical notes from eight different instruments were generated using the Flat.io platform. These instruments include violin, classical guitar, electric guitar, harp, piano, viola, double bass, and electric bass guitar. Notes for each instrument were created in whole, half, and quarter measures, resulting in a total of 1,020 note sounds. The notes were organized and categorized by instrument type.The data was divided into training and validation sets at an 80%-20% ratio. Preprocessing steps were applied to make the audio files compatible with transformer models; sampling rates were adjusted, stereo channels were converted to mono, and the data was formatted appropriately. The prepared dataset was used in the Google Colab environment for classification tasks with transformer models. The transformer model codes were analyzed and developed using the Hugging Face library. During the experimental phase, the performance of different transformer models was compared, demonstrating their effectiveness in sound classification tasks. The results indicate that transformer models are robust tools for enhancing sound classification performance, successfully distinguishing between various sounds. The proposed method shows promise for applications such as note differentiation, music analytics, instrument identification, and octave classification. This project represents a significant step forward in demonstrating the impact of deep learning-based methods on audio data.

## Keywords: Sound Classification, Transformer Models, Deep Learning, Musical Instruments, Note Classification, Data Preprocessing.
